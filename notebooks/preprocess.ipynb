{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from skimage.transform import resize\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_LOCATION = '../data/'\n",
    "TRAIN_IMAGES_LOCATION = '../data/train_images/'\n",
    "IMAGE_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(DATA_LOCATION + 'train_onelabel.csv')\n",
    "train_labels = train_labels.rename(columns={'image': 'filepath'})\n",
    "#train_labels = train_labels.sample(n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image(row):\n",
    "    \"\"\"\n",
    "    Load image from filepath to a numpy.ndarray\n",
    "    input:\n",
    "        - filepath: string with relative or absolute path to image\n",
    "    output:\n",
    "        - img:\n",
    "            numpy.ndarray containing the image\n",
    "            shaped (M,N), values [0.0, 1.0]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = TRAIN_IMAGES_LOCATION + row['filepath']\n",
    "        img = mpimg.imread(img)\n",
    "    except:\n",
    "        img = row\n",
    "        img = mpimg.imread(img)\n",
    "    img = np.absolute(np.divide(img.astype(float), 255) - 1.0)\n",
    "    return img\n",
    "\n",
    "def get_padding(i):\n",
    "    \"\"\"\n",
    "    Helper function for getting right padding sizes\n",
    "    input:\n",
    "        - i: positive integer gotten from substracting height and width of an image\n",
    "    output:\n",
    "        - Tuple representing the correct padding\n",
    "    \"\"\"\n",
    "    if i%2 == 0:\n",
    "        return (int(i/2),int(i/2))\n",
    "    else:\n",
    "        return (int(i/2-.5), int(i/2+.5))\n",
    "    \n",
    "def pad_image(img):\n",
    "    \"\"\"\n",
    "    Add padding to image to make it square\n",
    "    input:\n",
    "        - img: numpy array (2D) representing image\n",
    "    output:\n",
    "        - padded array of shape (N,N)\n",
    "    \"\"\"\n",
    "    H, W = img.shape\n",
    "    if H == W:\n",
    "        return img\n",
    "    elif H > W:\n",
    "        return np.pad(img, ((0,0), get_padding(H-W)), 'constant')\n",
    "    else:\n",
    "        return np.pad(img, (get_padding(W-H), (0,0)), 'constant')\n",
    "    \n",
    "def resize_image(img, size):\n",
    "    \"\"\"\n",
    "    Resize image to new square shape\n",
    "    input:\n",
    "        - img: numpy array (2D) representing image\n",
    "        - size: final shape of image in pixels (integer)\n",
    "    \"\"\"\n",
    "    return resize(img, (size,size), mode='reflect')\n",
    "\n",
    "def flattened_image(row):\n",
    "    \"\"\"\n",
    "    Loads and processes image to be used later on\n",
    "    input:\n",
    "        - row: Pandas.DataFrame row\n",
    "    output:\n",
    "        - Python list, flattened np.ndarray\n",
    "    \"\"\"\n",
    "    img = get_image(row)\n",
    "    img = pad_image(img)\n",
    "    img = resize_image(img, IMAGE_SIZE)\n",
    "    return img.flatten().tolist()\n",
    "\n",
    "def get_shape(row):\n",
    "    \"\"\"\n",
    "    Loads and processes image to be used later on\n",
    "    input:\n",
    "        - row: Pandas.DataFrame row\n",
    "    output:\n",
    "        - tuple, with original image dimensions\n",
    "    \"\"\"\n",
    "    img = get_image(row)\n",
    "    return img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get image from file\n",
    "# pad the image to a sqaure\n",
    "# resize to IMAGE_SIZE\n",
    "# flatten and convert np.array to Python list\n",
    "train_labels['image'] = train_labels.apply(flattened_image, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>class</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13927</th>\n",
       "      <td>99403.jpg</td>\n",
       "      <td>61</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23527</th>\n",
       "      <td>87866.jpg</td>\n",
       "      <td>117</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19291</th>\n",
       "      <td>115349.jpg</td>\n",
       "      <td>99</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18872</th>\n",
       "      <td>130360.jpg</td>\n",
       "      <td>95</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12187</th>\n",
       "      <td>22280.jpg</td>\n",
       "      <td>58</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16664</th>\n",
       "      <td>71220.jpg</td>\n",
       "      <td>84</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21802</th>\n",
       "      <td>34607.jpg</td>\n",
       "      <td>105</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8172</th>\n",
       "      <td>99043.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>109124.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10753</th>\n",
       "      <td>114425.jpg</td>\n",
       "      <td>49</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filepath  class                                              image\n",
       "13927   99403.jpg     61  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "23527   87866.jpg    117  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "19291  115349.jpg     99  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "18872  130360.jpg     95  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "12187   22280.jpg     58  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "16664   71220.jpg     84  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "21802   34607.jpg    105  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "8172    99043.jpg     34  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "495    109124.jpg      2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "10753  114425.jpg     49  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x192161320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAG3tJREFUeJztnWuMHdWRx/+FedoQ/MSZ2MZjG8eO\nhdYG3RCioMg2CzHZCPZDRF4y1sqSv2RXjsgqwG60Sja7SvIlJB9WiZwlu/4QXnmtLZQXGMiCtCIe\nwA7YBr+wYw82MzZ2TByCsan9cHua6sr0mZ57u/vemfP/SaM5fU/f7rp9u25XnapTR1QVhJC4OK/T\nAhBC6oeKT0iEUPEJiRAqPiERQsUnJEKo+IRECBWfkAhpS/FFZJWIvCwie0Xk7rKEIoRUi7SawCMi\nEwDsBnATgMMAtgL4jKruLE88QkgVnN/Ge68DsFdV9wOAiDwI4DYAuYo/ffp07e3tbeOUhJAQBw4c\nwLFjx2Sk/dpR/FkADpntwwA+FHpDb28v+vr62jglISREo9EotF/lg3sisk5E+kSkb3BwsOrTEUIK\n0I7i9wOYY7ZnJ69lUNUNqtpQ1caMGTPaOB0hpCzaUfytABaKyDwRuRDApwFsLkcsQkiVtOzjq+pZ\nEfl7AL8CMAHAD1R1R2mSEUIqo53BPajqzwH8vCRZCCE1wcw9QiKEik9IhFDxCYkQKj4hEULFJyRC\nqPiERAgVn5AIoeITEiFUfEIihIpPSIRQ8QmJECo+IRFCxSckQqj4hEQIFZ+QCKHiExIhVHxCIoSK\nT0iEUPEJiRAqPiER0laxTRIXb731Vmb7oosuyt03b01GkRFXd+oIVt63334703fhhRfWLc6oOXLk\nCIC/lD0PPvEJiRAqPiERQsUnJELo45OWeeedd9K2992tz3zu3Lm0fcEFF1QvWAtY+U+cOJHpmzlz\nZt3ijJqenh4Axa/viE98EfmBiAyIyIvmtaki8qiI7En+T2lVYEJI/RQx9f8bwCr32t0AtqjqQgBb\nkm1CyBhhRFNfVf9XRHrdy7cBWJ60NwJ4EsBdJcpFuhAf1gqF5mzf7t270/bixYvLF6xk/HLu1m3p\n1nDkaGl1cG+mqh5J2kcBdL8TRAhJaXtUX5s/h8NnawAQkXUi0icifYODg+2ejhBSAq2O6r8mIj2q\nekREegAM5O2oqhsAbACARqOR+wMRIz67zW6fd15rv8n79u1L2wsWLGhNsBxGY+baDLKxYN5b/Occ\nL+a9pdUn/mYAa5L2GgCbyhGHEFIHRcJ5DwD4PwCLROSwiKwF8A0AN4nIHgB/nWwTQsYIRUb1P5PT\ndWPJshBCaoKZex2kCl+yt7e37WMU5dSpU2n7Pe95T6bv8OHDaXvevHm1yVQG49Gn9zBXn5AIoeIT\nEiE09QP4cFueCZhXdCL0nrI4duxYZnv69OmVnctOygGA06dPp21v6k+dOrUyOcrAf5ZWw6etUPS+\nqhI+8QmJECo+IRFCxSckQujjB3jzzTcz27ZAw6uvvpq2586dm9nviiuuKHT8Mny95557LrN98803\nj/oYRfHyeb/ecskll1QmR6v8+c9/TtsXX3xxrecOzfDrxOw/PvEJiRAqPiERQlM/wMSJE3O3Z82a\nlba9yX7mzJm0ffz48UzfH//4x7S9cOHCtmX07kiVeDM0VFf/T3/6U9ruZF16G7az8lYdzgu5cfb+\nADpTh5BPfEIihIpPSITQ1C8BbwJb03ao7PFw2FFmADh48GDaXrRoUaFzr1ixotB+VWCX1Dr//Oyt\nNGnSpLR96NChtD1nzpzMftYk9uZxK+Z30WW+qh4998e3rkU3LMnFJz4hEULFJyRCqPiERAh9/JoJ\n+XrWr3/99dfTdmimm8+es8evesaZ9eN9eMz6/Nav7+/vz+xnsxz9OEFRus1/Ho6zZ8+m7W6QkU98\nQiKEik9IhNDUrxlrfocKeFjz3pqJ/hjenLeLltS5ymtRt+J973tfZtt+tm4oUFEW/rN02yrBfOIT\nEiFUfEIihIpPSISMOR/frsnm/aaxsJxxURntfhMmTMj0+dCZxfr1f/jDH9L25ZdfPio5y8QWMJky\nZUqmz36H586da+n4dRbK9OSFT/135L/DTlNkCa05IvKEiOwUkR0isj55faqIPCoie5L/U0Y6FiGk\nOyjyU3kWwBdVdQmA6wF8XkSWALgbwBZVXQhgS7JNCBkDFFk77wiAI0n7DRHZBWAWgNsALE922wjg\nSQB3VSKlwRYx8LPbLr300qpP3zbWvLez1oBshlvIDbBmozcprYtgzXubCQgAkydPTttlmMrWnAey\nJr037/Oo0z0LLVFui6UA2ettC4wAwLRp04Y9vjftu80NHdU3LiK9AK4B8AyAmcmPAgAcBVBf0JgQ\n0haFFV9ELgXwEwBfUNVTtk+bP2fDZqOIyDoR6RORPptcQgjpHIUUX0QuQFPpf6iqP01efk1EepL+\nHgADw71XVTeoakNVGzNmzChDZkJIm4zo40vTIbkPwC5V/Zbp2gxgDYBvJP83VSKhw84I836aLWxZ\n5RpyZWH9bCDfDwylsnr/fGDg3d9fO/PNz/Cza+6Vca1CM+tsmC4U1qozLOdDh9Z3D60XYO+/0dAN\nfr2lSBz/IwBWA3hBRLYlr/0Tmgr/sIisBXAQwO3ViEgIKZsio/pPA8j7ubqxXHEIIXUw5jL3LN58\nsibryZMnM3226KJdPqnu5Yzs8b15nHe+0chhzXtbeNIXnbTXytf+zwtRhbjsssty+4qa8GXMzita\nz94XwwiZ9+MR5uoTEiFUfEIiZEyb+p68rDXf99JLL6XtBQsWZParuh5aaCmlkAvSCta890tt2dVs\nvWlvM9eKZkP6UXI7el/1iHbIPcsz78dT0Y9W4BOfkAih4hMSIVR8QiJkXPn4IT/N9n3gAx/I3W/7\n9u25+7Xi/4cKatZZHMP69EDYL7Z+vQ2Lennt+4oWmhiNb100tBoaN8n7zmLz6T184hMSIVR8QiJk\nXJn6IfJqo3nTc+nSpbl9r7zyStq2k1wajUZmv9AEm07Wh2sFa96HzON9+/ZltufPnz/s+0LhNl9D\nsag5bq+xN+1tmNFee39sW98/VOOw22rntcrYugsJIaVAxSckQqj4hETIuPXxi/rWRcNEANDb25u2\n582bl7Z9wcvTp08P2ways+eqDimFlsy25w7V6bf7+YKatpCI9emB/LRf/5mtz9xqGm1oTOX3v/99\n2rbfn8fOlPTX4+jRo2l71qxZhWTqdvjEJyRCqPiERMi4NfWrMKPzjunNaGva+tlt1hQ9cuRIps8W\nxLj66quHfU9IDr9v0dChP17eMmW+RuDu3bvT9qJFizJ9NgPyhhtuSNuhpaX857QzCq3r4GcThmot\nWpfMhvbs8mJA9rN5OezS3gcPHsz0zZ07F2MRPvEJiRAqPiERMm5N/W7FmtXvfe97M309PT1p25qb\ntnae3544cWKmz45Ot1o/0Ga/2cy6N954I7OfXfLrgQceyPTdcsstafvLX/5y2n766acz+33sYx9L\n23fccUemz5rY1jT3RT/seg02oxLI1tKz18aXGy/KlVdemdm2bkYrtQo7BZ/4hEQIFZ+QCKHiExIh\n9PE7SNGsQVuE02/70JNdOtyGwHyYq6jPb/19X4jje9/7Xtr+1Kc+lelbuHBh2r733nvT9mc/+9nM\nfk899VTavvPOOzN9999/f9q2hUQOHDiQ2e+qq65K2/5zlr1Ogj+G9evtUuS+Tn9oibFOMOITX0Qu\nFpHfish2EdkhIl9NXp8nIs+IyF4ReUhEqi1PSwgpjSKm/lsAVqrqUgDLAKwSkesBfBPAvap6FYAT\nANZWJyYhpEyKrJ2nAIZsxguSPwWwEsCQ3bYRwFcAfLd8Ecc2u3btymzbOn5l1Hb377EmsW37c1k3\nwIfpbLahXRrLZwJee+21aXv16tWZvsHBwbRtV6J97LHHMvutXfvu88JnxdkJNjYDL7RcV6vXNFQb\nsejxpkyZMurzdopCg3siMiFZKXcAwKMA9gE4qapDZUsOAxgf05YIiYBCiq+q51R1GYDZAK4DsLjo\nCURknYj0iUiffQoQQjrHqMJ5qnoSwBMAPgxgsogMuQqzAfTnvGeDqjZUtWEzrAghnWNEH19EZgB4\nW1VPisglAG5Cc2DvCQCfBPAggDUANlUpaDcT8g8XL84aR1u3bk3bNkUXyKaoWh/Rp6jalF07kw7I\nr9Ufqp0/adKkYd8DAKdOnUrb3//+9zN9v/nNb9L2L37xi0yfvSarVq0a9j0e6yMDwI4dO9K2DZX5\ncYL169enbZ/ebGcD2oKavjioLZjqLVOfWp1Ht/v1liLBxR4AG0VkApoWwsOq+oiI7ATwoIj8G4Dn\nAdxXoZyEkBIpMqr/OwDXDPP6fjT9fULIGKO70onGKN7Es+ExH3r64Ac/mHsca5aGarmHTPOimWp2\n1p0vCGL7bJagnUkHZE1xjz2mzc7zdfvsLDlfz866CPazLFmyJLOfXQ7cF/rwsxeHCGUyehcs5MrZ\nJcbsfv4785l8nYa5+oRECBWfkAihqd8i1qzzJbTzzMuRsJlxoZLX1hQP1YCzGXN+koiNBvg++z5b\ni86b6aHPacuI2ww8P3K/d+/etP31r38907dixYq0bbMQQ6v2eplsVMK6XaMZgQ/t6+sQ5uHvEUve\ndawySsAnPiERQsUnJEKo+IRECH38ADbTC8j6wtb/8uG10JJORf22UE18WxzDFrwI7RfCh5psOMsW\nr7QFLwBg586duce018oW5fR87WtfS9svvPBCpi+vvr/PZLRjEj58ascGqvCZ88Kn/nu3fnxIDjse\n4gt7lgmf+IRECBWfkAjpSlO/jAIVZRCqk2Yz03yml6VO87LV/XwhDhuisjMq/QSYa655N5Pb19Kz\nJrYNPz7++OOZ/ewyXHY/IOuq2Lr63jUJFeaw77NZgt6VarU2X96+/h7u73938qoNYQLZLEKbvej3\n865WO/CJT0iEUPEJiRAqPiERIkWLDJZBo9HQvr6+Effz6apFl3uuGnutbP166892E9ZnHhgYyPTN\nnj07bfvrbcNleW0g64PbcBsA7N+/P23bNGI/ay2EDdPZcJhPfw3NVrTHsPeRv++t/H5sx16fbrwX\ngXfHGhqNBvr6+kYcpOiOT0EIqRUqPiER0pXhvEOHDmW2bQZTJ+uaWfMqVLO+ahmtyW0zvQCgt7c3\nbVvz1Re5sDK/+eabmT772bwJb7Hugy+kauvgW3lD18rXurNhLuta+dls1vT3blfRmZJHjx5N2zNn\nzsz0VW3eFw0lluly8IlPSIRQ8QmJkK409f2kDmsK2ahAqH5dFdgac1dffXXa9uZZyHQL9dkRaJtN\n501Pix0x94QmjdgltEKZbyGsKe6Pb01R6xKEshx9kY68FYNDE2C2bduW6Vu2bNmwx/NYV8XvZ6+V\nLUsOlGN+lzFxa7TwiU9IhFDxCYkQKj4hEdKVPn7Il7FLHflCGTZstH379kyfDfnMnz8/bfuZXraQ\no5djwYIFadv6fb4uvQ2B+WPYsJrvs75qKAxls998Nl2ez+n3Cx3fzsKzNev9MUKZcBa7BJX3Z+0x\nfcacDe9ZH9xeeyDrd1ufHsgWCLWz8zz2mvpMRnt8O9sPyF+yrNsp/MRPlsp+XkQeSbbnicgzIrJX\nRB4SkWLlXgghHWc0pv56ALvM9jcB3KuqVwE4AWBtmYIRQqqjkKkvIrMB/A2AfwdwpzTttZUAhqov\nbATwFQDfrUDG3BCYNw2tuXbdda0t6xcyWfPMYx8OazWc10oxCL9arr0m1hQPuU/+GHm1+vx+1g0I\nHT/kEoQm7Vjz3p7bh9Rs6DPkuhUldO39ua1coXuz2yj6xP82gC8BGHJ+pgE4qapDTvZhALOGeyMh\npPsYUfFF5BMABlT12VZOICLrRKRPRPp8LjYhpDMUeeJ/BMCtInIAwINomvjfATBZRIbsmdkA+od7\ns6puUNWGqjb8RA5CSGcY0RFR1XsA3AMAIrIcwD+q6udE5EcAPonmj8EaAJuqErKov1vGrLiyj+F9\nWlun3o8Z2DCS9RG9H2x9cJvK6gmNV1gZQ/65nblXRsERX7DTyu/78kKJfsZg0SWo7fH9Mew1CN0D\n/lrlXUebfg2Ew6edKPTRzlnuQnOgby+aPv995YhECKmaUQ09quqTAJ5M2vsBtDZ0TgjpKN0dcxij\nhOrU1TnOETJZrdnrw3c2RGXN7RA+i9K6J9bl8McLFQSx+1qXwNfft26RLdgBZE1sa0b7Jb9DWX2W\noq6gd8Hs9fH3RNFrXCbM1SckQqj4hEQITf0KsKO0RVesrZpQ1p03j/OKXoTq5YUy1Yqaxz4rzprE\n1nUIXVM/ep634m6rxUc8eZ/Nj87bbX+t7AQy2xdyAdoti88nPiERQsUnJEKo+IRECH38FrF+vC8M\nUTSTrE5G44Pn+fWtZpUVnXUY8n1Dy2SFyFsXwGdDtrpMdhnkfbZQiNQzdA/6IiJ58IlPSIRQ8QmJ\nEJr6oyDP7PWmWjeurhoiFB4rQ347YcVfq5CJbfctwxS3oT3vVpw8eTJtT548OdNXtukfCovavpBp\n/+qrr2a2X3/9dQB/OdEpj+6/KwkhpUPFJyRCqPiERAh9/FFgfTG7rLKtG18FIZ/Qh3ysP23TUkMh\nO5/OG1oau6iMFlsM0/v4Rf3nvFr/ozmG/Vz9/dmCUaHa/2WH+kLHKHp8v+z50HbRYil84hMSIVR8\nQiKEpv4osCZf1QU1QualDRf6mXUh8z4PWwcQyC5lXdTMDfW1WqvPntuGHEOuT1G8qWyvabsz38YC\nfOITEiFUfEIihKb+KNi8eXPavvXWWys9V6hE9/Hjx9N2qy6HPb417YH84hUh/OQQm/FXdOKIJ+8a\n2CgBUM6KtVZGnzEXWtF3rMInPiERQsUnJEKo+IREyPhwWCrC+9bWr7f+Z8i/9TXUQzOurG996tSp\ntD1t2rTMfmWHEn04LBQ6yyNUzLOMwiRWRl8oM68o52iwvvvGjRszfXfccUdLx+xmCil+smDmGwDO\nATirqg0RmQrgIQC9AA4AuF1VT+QdgxDSPYzG1F+hqstUtZFs3w1gi6ouBLAl2SaEjAHaMfVvA7A8\naW9Ec029u9qUp3ZCWWB+Sae8DDRfrMKavU899VSmz7oFy5cvz/TZ0FnRJZ3KYDTuiMVeu1DYr4xi\nHqHsPFubr4x6+atXr85sb9u2LW0vXbo0V666a/W1Q9FvRAH8WkSeFZF1yWszVfVI0j4KYGbp0hFC\nKqHoE/8GVe0XkSsAPCoiL9lOVVURGXYUKPmhWAcAV155ZVvCEkLKodATX1X7k/8DAH6G5vLYr4lI\nDwAk/wdy3rtBVRuq2qhzpVhCSD4jPvFFZBKA81T1jaR9M4B/BbAZwBoA30j+b6pS0E7g12HLw4fz\nrL+7cuXK3PeFQmUhf7HswhBejqIhvAMHDqTt3t7e3GNUXcjCr7nXCqE1AufPn5+29+zZk+l7//vf\n3/a5O0ERU38mgJ8lF/t8APer6i9FZCuAh0VkLYCDAG6vTkxCSJmMqPiquh/A0mFePw7gxiqEIoRU\nS/SZe2XUaG+lRl075y47bOSPl3f8odrtQ8ybN6/Q8VudnVcUK++ZM2cyfTY0GQpT2mP4/ezsP5+F\naGse5hUO6UaYq09IhFDxCYkQKj4hERK9j98qVVdiqXPZ5qLHnzJlSmbb+u6hcYJWZ8wVxV4r/71U\nPR5izzceU3YJIeMIKj4hEdKVpn6rGW1VU+fy16HPWUbhibwlv31faPZZK99FGTXxQ/jjDQ4Opm2b\nMl7WeceSeW/hE5+QCKHiExIhXWnq+xVgW82Mq5I6zX5P1aPkVZqvVU9y8bLb1XnHqlleBXziExIh\nVHxCIoSKT0iEdKWP340+PVC/L18lnfJ3qyhcEfos1scn7zJ+7mRCSGGo+IRECBWfkAih4hMSIVR8\nQiKEik9IhFDxCYkQKj4hEULFJyRCqPiEREghxReRySLyYxF5SUR2iciHRWSqiDwqInuS/1NGPhIh\npBso+sT/DoBfqupiNJfT2gXgbgBbVHUhgC3JNiFkDDCi4ovI5QA+CuA+AFDVM6p6EsBtADYmu20E\n8LdVCUkIKZciT/x5AAYB/JeIPC8i/5kslz1TVY8k+xxFc1VdQsgYoIjinw/gWgDfVdVrAJyGM+u1\nWTp12NK4IrJORPpEpM9WPCWEdI4iin8YwGFVfSbZ/jGaPwSviUgPACT/B4Z7s6puUNWGqjZseWNC\nSOcYUfFV9SiAQyKyKHnpRgA7AWwGsCZ5bQ2ATZVISAgpnaIVeP4BwA9F5EIA+wH8HZo/Gg+LyFoA\nBwHcXo2IhJCyKaT4qroNQGOYrhvLFYcQUgfM3CMkQqj4hEQIFZ+QCKHiExIhVHxCIoSKT0iEUPEJ\niRBpptnXdDKRQTSTfaYDOFbbiYenG2QAKIeHcmQZrRxzVXXE3PhaFT89qUifqg6XEBSVDJSDcnRK\nDpr6hEQIFZ+QCOmU4m/o0Hkt3SADQDk8lCNLJXJ0xMcnhHQWmvqEREitii8iq0TkZRHZKyK1VeUV\nkR+IyICIvGheq708uIjMEZEnRGSniOwQkfWdkEVELhaR34rI9kSOryavzxORZ5Lv56Gk/kLliMiE\npJ7jI52SQ0QOiMgLIrJNRPqS1zpxj9RSyr42xReRCQD+A8AtAJYA+IyILKnp9P8NYJV7rRPlwc8C\n+KKqLgFwPYDPJ9egblneArBSVZcCWAZglYhcD+CbAO5V1asAnACwtmI5hliPZsn2ITolxwpVXWbC\nZ524R+opZa+qtfwB+DCAX5ntewDcU+P5ewG8aLZfBtCTtHsAvFyXLEaGTQBu6qQsACYCeA7Ah9BM\nFDl/uO+rwvPPTm7mlQAeASAdkuMAgOnutVq/FwCXA3gFydhblXLUaerPAnDIbB9OXusUHS0PLiK9\nAK4B8EwnZEnM621oFkl9FMA+ACdV9WyyS13fz7cBfAnAO8n2tA7JoQB+LSLPisi65LW6v5faStlz\ncA/h8uBVICKXAvgJgC+o6qlOyKKq51R1GZpP3OsALK76nB4R+QSAAVV9tu5zD8MNqnotmq7o50Xk\no7azpu+lrVL2o6FOxe8HMMdsz05e6xSFyoOXjYhcgKbS/1BVf9pJWQBAm6siPYGmST1ZRIbqMNbx\n/XwEwK0icgDAg2ia+9/pgBxQ1f7k/wCAn6H5Y1j399JWKfvRUKfibwWwMBmxvRDAp9Es0d0pai8P\nLiKC5lJku1T1W52SRURmiMjkpH0JmuMMu9D8AfhkXXKo6j2qOltVe9G8Hx5X1c/VLYeITBKRy4ba\nAG4G8CJq/l60zlL2VQ+auEGKjwPYjaY/+c81nvcBAEcAvI3mr+paNH3JLQD2AHgMwNQa5LgBTTPt\ndwC2JX8fr1sWAH8F4PlEjhcB/Evy+nwAvwWwF8CPAFxU43e0HMAjnZAjOd/25G/H0L3ZoXtkGYC+\n5Lv5HwBTqpCDmXuERAgH9wiJECo+IRFCxSckQqj4hEQIFZ+QCKHiExIhVHxCIoSKT0iE/D/nLCZ0\nKpNHvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a51feba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = train_labels.sample(n=1).iloc[0]['image']\n",
    "plt.imshow(np.asarray(example).reshape(IMAGE_SIZE,IMAGE_SIZE),cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the labels from integer to categorical data\n",
    "train_labels_one_hot = to_categorical(train_labels['class'])\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(train_labels['class'])\n",
    "nClasses = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_labels['image'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24204,), (4096,)\n",
      "(24204, 4096)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_data)):\n",
    "    train_data[i] = np.asarray(train_data[i])\n",
    "\n",
    "print('{}, {}'.format(train_data.shape, train_data[0].shape))\n",
    "train_data = np.array(train_data.tolist())\n",
    "print('{}'.format(train_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24204/24204 [==============================] - 17s - loss: 3.5298 - acc: 0.2129    \n",
      "Epoch 2/20\n",
      "24204/24204 [==============================] - 14s - loss: 2.8351 - acc: 0.3193    \n",
      "Epoch 3/20\n",
      "24204/24204 [==============================] - 14s - loss: 2.5027 - acc: 0.3773    \n",
      "Epoch 4/20\n",
      "24204/24204 [==============================] - 15s - loss: 2.2880 - acc: 0.4097    \n",
      "Epoch 5/20\n",
      "24204/24204 [==============================] - 14s - loss: 2.1467 - acc: 0.4359    \n",
      "Epoch 6/20\n",
      "24204/24204 [==============================] - 15s - loss: 2.0256 - acc: 0.4591    \n",
      "Epoch 7/20\n",
      "24204/24204 [==============================] - 16s - loss: 1.9291 - acc: 0.4773    \n",
      "Epoch 8/20\n",
      "24204/24204 [==============================] - 17s - loss: 1.8496 - acc: 0.4934    - ETA: 1s - loss: 1.8469 - acc:\n",
      "Epoch 9/20\n",
      "24204/24204 [==============================] - 17s - loss: 1.7808 - acc: 0.5094    \n",
      "Epoch 10/20\n",
      "24204/24204 [==============================] - 15s - loss: 1.7156 - acc: 0.5165    \n",
      "Epoch 11/20\n",
      "24204/24204 [==============================] - 15s - loss: 1.6563 - acc: 0.5368    \n",
      "Epoch 12/20\n",
      "24204/24204 [==============================] - 14s - loss: 1.6027 - acc: 0.5468    \n",
      "Epoch 13/20\n",
      "24204/24204 [==============================] - 15s - loss: 1.5466 - acc: 0.5623    \n",
      "Epoch 14/20\n",
      "24204/24204 [==============================] - 14s - loss: 1.5215 - acc: 0.5649    \n",
      "Epoch 15/20\n",
      "24204/24204 [==============================] - 15s - loss: 1.4754 - acc: 0.5750    \n",
      "Epoch 16/20\n",
      "24204/24204 [==============================] - 15s - loss: 1.4326 - acc: 0.5885    \n",
      "Epoch 17/20\n",
      "24204/24204 [==============================] - 15s - loss: 1.4049 - acc: 0.5947    \n",
      "Epoch 18/20\n",
      "24204/24204 [==============================] - 14s - loss: 1.3671 - acc: 0.6035    \n",
      "Epoch 19/20\n",
      "24204/24204 [==============================] - 13s - loss: 1.3408 - acc: 0.6085    \n",
      "Epoch 20/20\n",
      "24204/24204 [==============================] - 12s - loss: 1.3201 - acc: 0.6175    \n"
     ]
    }
   ],
   "source": [
    "model_reg = Sequential()\n",
    "model_reg.add(Dense(512, activation='relu', input_shape=(IMAGE_SIZE**2,)))\n",
    "model_reg.add(Dropout(0.5))\n",
    "model_reg.add(Dense(512, activation='relu'))\n",
    "model_reg.add(Dropout(0.5))\n",
    "model_reg.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "model_reg.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_reg = model_reg.fit(train_data, train_labels_one_hot, batch_size=256, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg.save('../data/output/models/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
