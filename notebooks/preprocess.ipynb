{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from skimage.transform import resize\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_LOCATION = '../data/'\n",
    "TRAIN_IMAGES_LOCATION = '../data/train_images/'\n",
    "IMAGE_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(DATA_LOCATION + 'train_onelabel.csv')\n",
    "train_labels = train_labels.rename(columns={'image': 'filepath'})\n",
    "#train_labels = train_labels.sample(n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image(row):\n",
    "    \"\"\"\n",
    "    Load image from filepath to a numpy.ndarray\n",
    "    input:\n",
    "        - filepath: string with relative or absolute path to image\n",
    "    output:\n",
    "        - img:\n",
    "            numpy.ndarray containing the image\n",
    "            shaped (M,N), values [0.0, 1.0]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = TRAIN_IMAGES_LOCATION + row['filepath']\n",
    "        img = mpimg.imread(img)\n",
    "    except:\n",
    "        img = row\n",
    "        img = mpimg.imread(img)\n",
    "    img = np.absolute(np.divide(img.astype(float), 255) - 1.0)\n",
    "    return img\n",
    "\n",
    "def get_padding(i):\n",
    "    \"\"\"\n",
    "    Helper function for getting right padding sizes\n",
    "    input:\n",
    "        - i: positive integer gotten from substracting height and width of an image\n",
    "    output:\n",
    "        - Tuple representing the correct padding\n",
    "    \"\"\"\n",
    "    if i%2 == 0:\n",
    "        return (int(i/2),int(i/2))\n",
    "    else:\n",
    "        return (int(i/2-.5), int(i/2+.5))\n",
    "    \n",
    "def pad_image(img):\n",
    "    \"\"\"\n",
    "    Add padding to image to make it square\n",
    "    input:\n",
    "        - img: numpy array (2D) representing image\n",
    "    output:\n",
    "        - padded array of shape (N,N)\n",
    "    \"\"\"\n",
    "    H, W = img.shape\n",
    "    if H == W:\n",
    "        return img\n",
    "    elif H > W:\n",
    "        return np.pad(img, ((0,0), get_padding(H-W)), 'constant')\n",
    "    else:\n",
    "        return np.pad(img, (get_padding(W-H), (0,0)), 'constant')\n",
    "    \n",
    "def resize_image(img, size):\n",
    "    \"\"\"\n",
    "    Resize image to new square shape\n",
    "    input:\n",
    "        - img: numpy array (2D) representing image\n",
    "        - size: final shape of image in pixels (integer)\n",
    "    \"\"\"\n",
    "    return resize(img, (size,size), mode='reflect')\n",
    "\n",
    "def flattened_image(row):\n",
    "    \"\"\"\n",
    "    Loads and processes image to be used later on\n",
    "    input:\n",
    "        - row: Pandas.DataFrame row\n",
    "    output:\n",
    "        - Python list, flattened np.ndarray\n",
    "    \"\"\"\n",
    "    img = get_image(row)\n",
    "    img = pad_image(img)\n",
    "    img = resize_image(img, IMAGE_SIZE)\n",
    "    return img.flatten().tolist()\n",
    "\n",
    "def get_shape(row):\n",
    "    \"\"\"\n",
    "    Loads and processes image to be used later on\n",
    "    input:\n",
    "        - row: Pandas.DataFrame row\n",
    "    output:\n",
    "        - tuple, with original image dimensions\n",
    "    \"\"\"\n",
    "    img = get_image(row)\n",
    "    return img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get image from file\n",
    "# pad the image to a sqaure\n",
    "# resize to IMAGE_SIZE\n",
    "# flatten and convert np.array to Python list\n",
    "train_labels['image'] = train_labels.apply(flattened_image, axis=1)\n",
    "\n",
    "# get original shape, just in case\n",
    "# not really needed, so commented out\n",
    "# train_labels['original_shape'] = train_labels.apply(get_shape, axis=1)\n",
    "\n",
    "# and do we need train_labels['filepath']?\n",
    "# could be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>class</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22339</th>\n",
       "      <td>26777.jpg</td>\n",
       "      <td>108</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12918</th>\n",
       "      <td>63350.jpg</td>\n",
       "      <td>58</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13049</th>\n",
       "      <td>121866.jpg</td>\n",
       "      <td>58</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10731</th>\n",
       "      <td>131779.jpg</td>\n",
       "      <td>49</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>113706.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>148010.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22919</th>\n",
       "      <td>63252.jpg</td>\n",
       "      <td>113</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20604</th>\n",
       "      <td>123495.jpg</td>\n",
       "      <td>101</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>31339.jpg</td>\n",
       "      <td>27</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14629</th>\n",
       "      <td>111032.jpg</td>\n",
       "      <td>67</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filepath  class                                              image\n",
       "22339   26777.jpg    108  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "12918   63350.jpg     58  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "13049  121866.jpg     58  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "10731  131779.jpg     49  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1318   113706.jpg      4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1295   148010.jpg      4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "22919   63252.jpg    113  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "20604  123495.jpg    101  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "6085    31339.jpg     27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "14629  111032.jpg     67  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19bda1da0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7z5NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19bd4e828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = train_labels.sample(n=1).iloc[0]['image']\n",
    "plt.imshow(np.asarray(example).reshape(IMAGE_SIZE,IMAGE_SIZE),cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the labels from integer to categorical data\n",
    "train_labels_one_hot = to_categorical(train_labels['class'])\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(train_labels['class'])\n",
    "nClasses = 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_labels['image'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24204,), (4096,)\n",
      "(24204, 4096)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_data)):\n",
    "    train_data[i] = np.asarray(train_data[i])\n",
    "\n",
    "print('{}, {}'.format(train_data.shape, train_data[0].shape))\n",
    "train_data = np.array(train_data.tolist())\n",
    "print('{}'.format(train_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24204/24204 [==============================] - 15s - loss: 3.1269 - acc: 0.2817    \n",
      "Epoch 2/20\n",
      "24204/24204 [==============================] - 13s - loss: 2.2543 - acc: 0.4276    \n",
      "Epoch 3/20\n",
      "24204/24204 [==============================] - 12s - loss: 1.8666 - acc: 0.5013    \n",
      "Epoch 4/20\n",
      "24204/24204 [==============================] - 12s - loss: 1.6127 - acc: 0.5545    \n",
      "Epoch 5/20\n",
      "24204/24204 [==============================] - 12s - loss: 1.4021 - acc: 0.6039    \n",
      "Epoch 6/20\n",
      "24204/24204 [==============================] - 12s - loss: 1.2179 - acc: 0.6498    \n",
      "Epoch 7/20\n",
      "24204/24204 [==============================] - 13s - loss: 1.0657 - acc: 0.6880    \n",
      "Epoch 8/20\n",
      "24204/24204 [==============================] - 14s - loss: 0.9252 - acc: 0.7265    \n",
      "Epoch 9/20\n",
      "24204/24204 [==============================] - 13s - loss: 0.8042 - acc: 0.7617    \n",
      "Epoch 10/20\n",
      "24204/24204 [==============================] - 14s - loss: 0.6931 - acc: 0.7938    \n",
      "Epoch 11/20\n",
      "24204/24204 [==============================] - 13s - loss: 0.6050 - acc: 0.8179    \n",
      "Epoch 12/20\n",
      "24204/24204 [==============================] - 14s - loss: 0.5271 - acc: 0.8411    \n",
      "Epoch 13/20\n",
      "24204/24204 [==============================] - 14s - loss: 0.4521 - acc: 0.8633    \n",
      "Epoch 14/20\n",
      "24204/24204 [==============================] - 14s - loss: 0.3930 - acc: 0.8802    \n",
      "Epoch 15/20\n",
      "24204/24204 [==============================] - 14s - loss: 0.3406 - acc: 0.8952    \n",
      "Epoch 16/20\n",
      "24204/24204 [==============================] - 14s - loss: 0.3038 - acc: 0.9073    \n",
      "Epoch 17/20\n",
      "24204/24204 [==============================] - 13s - loss: 0.2608 - acc: 0.9227    \n",
      "Epoch 18/20\n",
      "24204/24204 [==============================] - 12s - loss: 0.2297 - acc: 0.9316    \n",
      "Epoch 19/20\n",
      "24204/24204 [==============================] - 14s - loss: 0.2046 - acc: 0.9392    \n",
      "Epoch 20/20\n",
      "24204/24204 [==============================] - 13s - loss: 0.1851 - acc: 0.9448    \n"
     ]
    }
   ],
   "source": [
    "# this doesn't work :(\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(IMAGE_SIZE**2,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24204/24204 [==============================] - 14s - loss: 3.5212 - acc: 0.2134    \n",
      "Epoch 2/20\n",
      "24204/24204 [==============================] - 14s - loss: 2.8149 - acc: 0.3259    \n",
      "Epoch 3/20\n",
      "24204/24204 [==============================] - 13s - loss: 2.4870 - acc: 0.3795    \n",
      "Epoch 4/20\n",
      "24204/24204 [==============================] - 13s - loss: 2.2827 - acc: 0.4150    \n",
      "Epoch 5/20\n",
      "24204/24204 [==============================] - 14s - loss: 2.1341 - acc: 0.4384    \n",
      "Epoch 6/20\n",
      "24204/24204 [==============================] - 17s - loss: 2.0149 - acc: 0.4608    \n",
      "Epoch 7/20\n",
      "24204/24204 [==============================] - 18s - loss: 1.9229 - acc: 0.4773    \n",
      "Epoch 8/20\n",
      "24204/24204 [==============================] - 14s - loss: 1.8347 - acc: 0.4975    \n",
      "Epoch 9/20\n",
      "24204/24204 [==============================] - 13s - loss: 1.7663 - acc: 0.5105    \n",
      "Epoch 10/20\n",
      "24204/24204 [==============================] - 13s - loss: 1.7012 - acc: 0.5259    \n",
      "Epoch 11/20\n",
      "24204/24204 [==============================] - 14s - loss: 1.6373 - acc: 0.5359    \n",
      "Epoch 12/20\n",
      "24204/24204 [==============================] - 14s - loss: 1.5923 - acc: 0.5527    \n",
      "Epoch 13/20\n",
      "24204/24204 [==============================] - 14s - loss: 1.5365 - acc: 0.5622    \n",
      "Epoch 14/20\n",
      "24204/24204 [==============================] - 14s - loss: 1.5083 - acc: 0.5710    \n",
      "Epoch 15/20\n",
      "24204/24204 [==============================] - 17s - loss: 1.4695 - acc: 0.5770    \n",
      "Epoch 16/20\n",
      "24204/24204 [==============================] - 20s - loss: 1.4166 - acc: 0.5908    \n",
      "Epoch 17/20\n",
      "24204/24204 [==============================] - 14s - loss: 1.4030 - acc: 0.5979    \n",
      "Epoch 18/20\n",
      "24204/24204 [==============================] - 13s - loss: 1.3669 - acc: 0.6030    \n",
      "Epoch 19/20\n",
      "24204/24204 [==============================] - 13s - loss: 1.3276 - acc: 0.6139    \n",
      "Epoch 20/20\n",
      "24204/24204 [==============================] - 13s - loss: 1.2974 - acc: 0.6198    \n"
     ]
    }
   ],
   "source": [
    "model_reg = Sequential()\n",
    "model_reg.add(Dense(512, activation='relu', input_shape=(IMAGE_SIZE**2,)))\n",
    "model_reg.add(Dropout(0.5))\n",
    "model_reg.add(Dense(512, activation='relu'))\n",
    "model_reg.add(Dropout(0.5))\n",
    "model_reg.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "model_reg.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_reg = model_reg.fit(train_data, train_labels_one_hot, batch_size=256, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
